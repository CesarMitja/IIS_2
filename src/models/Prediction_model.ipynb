{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Določimo poti do datotek in direktorijev\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)))  \u001b[38;5;66;03m# Dobi pot do direktorija nad 'src'\u001b[39;00m\n\u001b[0;32m     14\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_for_prediction.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m scaler_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Določimo poti do datotek in direktorijev\n",
    "base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Dobi pot do direktorija nad 'src'\n",
    "data_path = os.path.join(base_dir, 'data', 'processed', 'data_for_prediction.csv')\n",
    "scaler_path = os.path.join(base_dir, 'models', 'scaler.pkl')\n",
    "model_path = os.path.join(base_dir, 'models', 'rnn_model.pth')\n",
    "train_metrics_path = os.path.join(base_dir, 'reports', 'train_metrics.txt')\n",
    "test_metrics_path = os.path.join(base_dir, 'reports', 'test_metrics.txt')\n",
    "\n",
    "# Naložimo in pripravimo podatke\n",
    "data = pd.read_csv(data_path, parse_dates=['date'])\n",
    "features = ['temperature', 'relative_humidity', 'dew_point', 'apparent_temperature',\n",
    "            'precipitation_probability', 'rain', 'surface_pressure', 'bike_stands', 'available_bike_stands']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Shranjevanje scaler-ja\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Ustvarjanje sekvenčnih podatkov\n",
    "def create_sequences(data, input_width, forecast_horizon):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - input_width - forecast_horizon + 1):\n",
    "        X.append(data[i:(i+input_width), :])\n",
    "        y.append(data[(i+input_width):(i+input_width+forecast_horizon), -1])  # Zadnji stolpec je 'available_bike_stands'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "input_width = 72\n",
    "forecast_horizon = 10\n",
    "\n",
    "X, y = create_sequences(data[features].values, input_width, forecast_horizon)\n",
    "# Ustvarimo učno in testno množico\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "# Pretvorba v PyTorch tenzorje\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# DataLoader za učno in testno množico\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.linear(hn[-1])\n",
    "        return out\n",
    "\n",
    "model = RNNModel(input_size=len(features), hidden_size=50, num_layers=1, output_size=forecast_horizon)\n",
    "\n",
    "# Definicija kriterija (izgube) in optimizatorja\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Funkcija za treniranje\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.view(targets.size(0), -1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss}')\n",
    "    return train_losses\n",
    "\n",
    "# Funkcija za testiranje\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets.view(targets.size(0), -1))\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    return test_loss\n",
    "\n",
    "# Učenje modela in shranjevanje zadnje izgube\n",
    "train_losses = train_model(model, train_loader, criterion, optimizer, num_epochs=20)\n",
    "\n",
    "# Evaluacija modela\n",
    "test_loss = evaluate_model(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Shranjevanje modela in metrik\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "with open(train_metrics_path, 'w') as f:\n",
    "    f.write(f'Training Losses: {train_losses}\\n')\n",
    "with open(test_metrics_path, 'w') as f:\n",
    "    f.write(f'Test Loss: {test_loss}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
